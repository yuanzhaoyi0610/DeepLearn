{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入open方法\n",
    "from io import open\n",
    "# 用于字符规范化\n",
    "import unicodedata\n",
    "# 导入正则表达式的包\n",
    "import re\n",
    "# 导入随机处理数据的包\n",
    "import random\n",
    "# 导入torch相关的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# 导入优化方法的工具包\n",
    "from torch import optim\n",
    "\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# 设备的选择, 可以选择在GPU上运行或者在CPU上运行\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义起始标志\n",
    "SOS_token = 0\n",
    "# 定义结束标志\n",
    "EOS_token = 1\n",
    "data_path = 'data/eng-fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang():\n",
    "    def __init__(self, name):\n",
    "        # name: 参数代表传入某种语言的名字\n",
    "        self.name = name\n",
    "        # 初始化单词到索引的映射字典\n",
    "        self.word2index = {}\n",
    "        # 初始化索引到单词的映射字典, 其中0, 1对应的SOS, EOS已经在字典中了\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        # 初始化词汇对应的数字索引, 从2开始, 因为0, 1已经被开始字符和结束字符占用了\n",
    "        self.n_words = 2\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        # 添加句子的函数, 将整个句子中所有的单词依次添加到字典中\n",
    "        # 因为英文, 法文都是空格进行分割的语言, 直接进行分词就可以\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        # 添加单词到类内字典中, 将单词转换为数字\n",
    "        # 首先判断word是否已经在self.word2index字典的key中\n",
    "        if word not in self.word2index:\n",
    "            # 添加的时候, 索引值取当前类中单词的总数量\n",
    "            self.word2index[word] = self.n_words\n",
    "            # 再添加翻转的字典\n",
    "            self.index2word[self.n_words] = word\n",
    "            # 第三步更新类内的单词总数量\n",
    "            self.n_words += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    # since: 代表模型训练的开始时间\n",
    "    # 首先获取当前时间\n",
    "    now = time.time()\n",
    "    # 计算得到时间差\n",
    "    s = now - since\n",
    "    # 将s转换为分钟, 秒的形式\n",
    "    m = math.floor(s / 60)\n",
    "    # 计算余数的秒\n",
    "    s -= m * 60\n",
    "    # 按照指定的格式返回时间差\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将unicode字符串转换为ASCII字符串, 主要用于将法文的重音符号去除掉\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "# 定义字符串规范化函数\n",
    "def normalizeString(s):\n",
    "    # 第一步使字符转变为小写并去除掉两侧的空白符, 再调用上面的函数转换为ASCII字符串\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    # 在.!?前面加一个空格\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    # 使用正则表达式将字符串中不是大小写字符和正常标点符号的全部替换成空格\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2):\n",
    "    # lang1: 代表源语言的名字\n",
    "    # lang2: 代表目标语言的名字\n",
    "    # 整个函数返回对应的两个类对象, 以及语言对的列表\n",
    "    lines = open(data_path, encoding='utf-8').read().strip().split('\\n')\n",
    "    # 对lines列表中的句子进行标准化处理, 并以\\t进行再次划分, 形成子列表\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    # 直接初始化两个类对象\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置组成句子中单词或标点的最多个数\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "# 选择带有指定前缀的英文源语言的语句数据作为训练数据\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "# 过滤语言对的具体逻辑函数\n",
    "def filterPair(pair):\n",
    "    # 当前传入的pair是一个语言对的形式\n",
    "    # pair[0]代表英文源语句, 长度应小于MAX_LENGTH， 并且以指定前缀开始\n",
    "    # pair[1]代表法文源语句, 长度应小于MAX_LENGTH\n",
    "    return len(pair[0].split(' ')) < MAX_LENGTH and pair[0].startswith(eng_prefixes) and len(pair[1].split(' ')) < MAX_LENGTH\n",
    "    #return len(pair[0].split(' ')) < MAX_LENGTH and len(pair[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# 过滤语言对的函数\n",
    "def filterPairs(pairs):\n",
    "    # 函数直接遍历列表中的每个语言字符串并调用filterPair()函数即可\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整合数据预处理的函数\n",
    "def prepareData(lang1, lang2):\n",
    "    # lang1: 代表源语言的名字, 英文\n",
    "    # lang2: 代表目标语言的名字, 法文\n",
    "    # 第一步通过调用readLangs()函数得到两个类对象, 并得到字符串类型的语言对的列表\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "    # 第二步对字符串类型的列表进行过滤操作\n",
    "    pairs = filterPairs(pairs)\n",
    "    # 对过滤后的语言对列表进行遍历操作, 添加进类对象中\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    # 返回数值映射后的类对象, 以及过滤后的语言对列表\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorFromSentence(lang, sentence):\n",
    "    # lang: 代表是Lang类的实例化对象\n",
    "    # sentence: 代表传入的语句\n",
    "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    # 注意要在最后添加一个语句的结束符号\n",
    "    indexes.append(EOS_token)\n",
    "    # 使用torch.tensor对列表进行封装, 并将其形状改变成 n*1\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    # pair: 代表一个语言对(英文, 法文)\n",
    "    # 依次调用具体的处理函数, 分别处理源语言和目标语言\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    output_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建编码器类\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # input_size: 代表编码器输入尺寸, 就是英文的词表大小\n",
    "        # hidden_size: 代表GRU的隐藏层神经单元数, 同时也是词嵌入的维度\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # 将参数传入类中\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # 实例化Embedding层, 输入参数分别是词表单词总数, 和词嵌入的维度\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # 实例化GRU, 参数也是hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input1, hidden):\n",
    "        # input1: 代表源语言中的输入张量\n",
    "        # hidden: 代表初始化的隐藏层张量\n",
    "        # 注意: 经过EMbedding处理后, 张量是一个二维张量, 但是GRU要求输入是三维张量,\n",
    "        # 所以要对结果进行扩展维度 view(), 同时让任意单词映射后的尺寸是[1, embedding]\n",
    "        output = self.embedding(input1).view(1, 1, -1)\n",
    "        # 将output和hidden传入GRU单元中, 得到返回结果\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        # 将隐藏层张量初始化为1*1*self.hidden_size大小的张量\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang, output_lang, pairs = prepareData('eng', 'fra')\n",
    "pair_tensor = tensorsFromPair(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建解码器类\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        # hidden_size: 代表隐藏层的神经元个数, 同时也是解码器的输入尺寸\n",
    "        # output_size: 代表整个解码器的输出尺寸, 指定的尺寸也就是目标语言的单词总数\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # 将参数传入类中\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # 实例化Embedding对象, 输入参数分别是目标语言的单词总数, 和词嵌入的维度\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # 实例化GRU对象\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # 实例化线性层的对象, 对GRU的输出做线性变换, 得到希望的输出尺寸output_size\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        # 最后进入Softmax的处理\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input1, hidden):\n",
    "        # input1: 代表目标语言的输入张量\n",
    "        # hidden: 代表初始化的GRU隐藏层张量\n",
    "        # 经历了Embedding层处理后, 要将张量形状改变为三维张量\n",
    "        output = self.embedding(input1).view(1, 1, -1)\n",
    "        # 使用relu函数对输出进行处理, 使得EMbedding矩阵更稀疏, 防止过拟合\n",
    "        output = F.relu(output)\n",
    "        # 将张量传入GRU解码器中\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # 经历GRU处理后的张量是三维张量, 但是全连接层需要二维张量, 利用output[0]来降维\n",
    "        output = self.softmax(self.linear(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        # 初始化隐藏层张量, 形状为1*1*self.hidden_size\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建基于GRU和Attention的解码器类\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        # hidden_size: 代表解码器的GRU输出尺寸, 就是隐藏层的神经元个数\n",
    "        # output_size: 指定的网络输出尺寸, 代表目标语言的词汇总数(法文)\n",
    "        # dropout_p: 使用Dropout层的置零比例\n",
    "        # max_length: 代表句子的最大长度\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        # 将参数传入类中\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # 实例化一个Embedding对象, 参数是目标语言的词汇总数和词嵌入的维度\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        \n",
    "        # 实例化第一个注意力层, 注意输入是两个张量的合并\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        \n",
    "        # 实例化第二个注意力层, 注意输入也是两个张量的合并, 同时输出要进入GRU中\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        # 实例化一个nn.Dropout层\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        # 实例化GRU单元\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        \n",
    "        # 实例化GRU之后的线性层, 作为整个解码器的输出\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, input1, hidden, encoder_output):\n",
    "        # input1: 源数据的输入张量\n",
    "        # hidden: 初始化的隐藏层张量\n",
    "        # encoder_output: 代表编码器的输出张量\n",
    "        # 对输入input1进行词嵌入处理, 并扩展维度\n",
    "        embedded = self.embedding(input1).view(1, 1, -1)\n",
    "        # 紧接着将其输入dropout层, 防止过拟合\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # 在进行第一个注意力层处理前, 要将Q, K进行纵轴拼接\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        # 进行bmm操作, 注意要将二维张量扩展成三维张量\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_output.unsqueeze(0))\n",
    "        \n",
    "        # 再次进行拼接, 顺便要进行一次降维\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        \n",
    "        # 将output输入第二个注意力层\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        # 使用relu进行激活层处理\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # 将激活后的张量, 连同隐藏层张量, 一起传入GRU中\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        # 最后将结果先降维, 然后线性层梳理成指定的输出维度, 最后经过softmax处理\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        # 返回解码器的最终输出结果, 最后的隐藏层张量, 注意力权重张量\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        # 初始化一个全零的隐藏层张量, 形状为 1*1*self.hidden_size\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定一下teacher_forcing的比率, 在多大的概率下使用这个策略进行训练\n",
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # input_tensor: 代表源语言的输入张量\n",
    "    # target_tensor: 代表目标语言的输入张量\n",
    "    # encoder: 代表编码器的实例化对象\n",
    "    # decoder: 代表解码器的实例化对象\n",
    "    # encoder_optimizer: 代表编码器优化器\n",
    "    # decoder_optimizer: 代表解码器优化器\n",
    "    # criterion: 损失函数\n",
    "    # max_length: 代表句子的最大长度\n",
    "    # 初始化编码器的隐藏层张量\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    # 训练前将编码器和解码器的优化器梯度归零\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # 根据源文本和目标文本张量获得对应的长度\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    # 初始化编码器的输出矩阵张量, 形状是max_length * encoder.hidden_size\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    \n",
    "    # 设置初始损失值\n",
    "    loss = 0\n",
    "    \n",
    "    # 遍历输入张量\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        # 每一个轮次的输出encoder_output是三维张量, 使用[0,0]进行降维到一维列表, 赋值给输出张量\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    \n",
    "    # 初始化解码器的第一个输入字符\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    \n",
    "    # 初始化解码器的隐藏层张量, 赋值给最后一次编码器的隐藏层张量\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # 判断是否使用teacher_forcing\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    # 如果使用teacher_forcing\n",
    "    if use_teacher_forcing:\n",
    "        # 遍历目标张量, 进行解码\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # 使用损失函数计算损失值, 并进行累加\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            # 因为使用了teacher_forcing, 所以将下一步的解码器输入强制设定为“正确的答案”\n",
    "            decoder_input = target_tensor[di]\n",
    "    # 如果不适用teacher_forcing\n",
    "    else:\n",
    "        # 遍历目标张量, 进行解码\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # 预测值变成输出张量中概率最大的那一个\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            # 使用损失函数计算损失值, 并进行累加\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            # 如果某一步的解码结果是句子终止符号, 则解码直接结束, 跳出循环\n",
    "            if topi.squeeze().item() == EOS_token:\n",
    "                break\n",
    "            # 下一步解码器的输入要设定为当前步最大概率值的那一个\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "    \n",
    "    # 应用反向传播进行梯度计算\n",
    "    loss.backward()\n",
    "    # 利用编码器和解码器的优化器进行参数的更新\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    # 返回平均损失\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建时间计算的辅助函数\n",
    "def timeSince(since):\n",
    "    # since: 代表模型训练的开始时间\n",
    "    # 首先获取当前时间\n",
    "    now = time.time()\n",
    "    # 计算得到时间差\n",
    "    s = now - since\n",
    "    # 将s转换为分钟, 秒的形式\n",
    "    m = math.floor(s / 60)\n",
    "    # 计算余数的秒\n",
    "    s -= m * 60\n",
    "    # 按照指定的格式返回时间差\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    # encoder: 编码器的实例化对象\n",
    "    # decoder: 解码器的实例化对象\n",
    "    # n_iters: 训练的总迭代步数\n",
    "    # print_every: 每隔多少轮次进行一次训练日志的打印\n",
    "    # plot_every: 每隔多少轮次进行一次损失值的添加, 为了后续绘制损失曲线\n",
    "    # learning_rate: 学习率\n",
    "    # 获取训练开始的时间\n",
    "    start = time.time()\n",
    "    # 初始化存放平均损失值的列表\n",
    "    plot_losses = []\n",
    "    # 每隔打印间隔的总损失值\n",
    "    print_loss_total = 0\n",
    "    # 每个绘制曲线损失值的列表\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    # 定义编码器和解码器的优化器\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # 定义损失函数\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # 按照设定的总迭代次数进行迭代训练\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        # 每次从语言对的列表中随机抽取一条样本作为本轮迭代的训练数据\n",
    "        training_pair = tensorsFromPair(random.choice(pairs))  #这里会得到([[4],[2]],[[3],[2],[5]]）\n",
    "        # 依次将选取出来的语句对作为输入张量, 和输出张量\n",
    "        input_tensor = training_pair[0]  #源语言\n",
    "        target_tensor = training_pair[1] #目的语言\n",
    "        \n",
    "        # 调用train()函数获得本轮迭代的损失值\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion)\n",
    "        # 将本轮迭代的损失值进行累加\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        # 如果到达了打印的轮次\n",
    "        if iter % print_every == 0:\n",
    "            # 首先获取本次打印的平均损失值\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            # 为了下一个打印间隔的累加, 这里将累加器清零\n",
    "            print_loss_total = 0\n",
    "            # 打印若干信息\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start),\n",
    "                            iter, iter / n_iters * 100, print_loss_avg))\n",
    "        \n",
    "        # 如果到达了绘制损失曲线的轮次\n",
    "        if iter % plot_every == 0:\n",
    "            # 首先获取本次损失添加的平均损失值\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            # 将平均损失值添加进最后的列表中\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            # 为了下一个添加损失值的累加, 这里将累加器清零\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    # 绘制损失曲线\n",
    "    plt.figure()\n",
    "    plt.plot(plot_losses)\n",
    "    plt.savefig(\"./s2s_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    # encoder: 代表编码器对象\n",
    "    # decoder: 代表解码器对象\n",
    "    # sentence: 待评估的源语句\n",
    "    # max_length: 句子的最大长度\n",
    "    # 注意: 整个评估过程梯度不进行改变\n",
    "    with torch.no_grad():\n",
    "        # 对输入语句进行张量表示\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        # 获得输入的句子长度\n",
    "        input_length = input_tensor.size(0)\n",
    "        # 初始化编码器的隐藏层张量\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        # 初始化编码器的输出张量, 矩阵的形状max_length * hidden_size\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        # 遍历输入张量\n",
    "        for ei in range(input_length):\n",
    "            # 循环进入编码器的处理\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            # 将三维张量的输出先进行降维到一维, 然后赋值给encoder_outputs\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        # 初始化解码器的第一个输入, 就是起始字符\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        # 初始化解码器的隐藏层输入\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # 初始化预测词汇的列表\n",
    "        decoded_words = []\n",
    "        # 初始化一个attention张量\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        # 遍历解码\n",
    "        for di in range(max_length):\n",
    "            # 将张量送入解码器处理\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # 首先将注意力张量保存\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            # 按照解码器输出的最高概率作为当前时间步的预测值\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            # 如果解析出的是结束字符\n",
    "            if topi.item() == EOS_token:\n",
    "                # 将结束字符添加到结果列表中, 并退出解码循环\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                # 要根据索引去将真实的字符添加进结果列表中\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            # 最后一步将预测的标签赋值给下一步解码器的输入\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        # 返回最终解码的结果列表, 以及注意力张量\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=6):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('源语言:', pair[0])\n",
    "        print('目的语言', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('翻译结果:', output_sentence)\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (2000 2%) 3.8922\n",
      "1m 30s (4000 4%) 3.3685\n",
      "2m 1s (6000 6%) 3.2014\n",
      "2m 31s (8000 8%) 3.0350\n",
      "3m 2s (10000 10%) 2.9072\n",
      "3m 33s (12000 12%) 2.7405\n",
      "4m 3s (14000 14%) 2.6468\n",
      "4m 34s (16000 16%) 2.5356\n",
      "5m 5s (18000 18%) 2.4957\n",
      "5m 37s (20000 20%) 2.3473\n",
      "6m 8s (22000 22%) 2.3221\n",
      "6m 38s (24000 24%) 2.2167\n",
      "7m 8s (26000 26%) 2.2068\n",
      "7m 38s (28000 28%) 2.0926\n",
      "8m 8s (30000 30%) 2.0138\n",
      "8m 39s (32000 32%) 1.9866\n",
      "9m 10s (34000 34%) 1.9608\n",
      "9m 41s (36000 36%) 1.8970\n",
      "10m 11s (38000 38%) 1.8591\n",
      "10m 42s (40000 40%) 1.8975\n",
      "11m 15s (42000 42%) 1.7534\n",
      "11m 48s (44000 44%) 1.6761\n",
      "12m 19s (46000 46%) 1.7070\n",
      "12m 50s (48000 48%) 1.6479\n",
      "13m 20s (50000 50%) 1.6117\n",
      "13m 50s (52000 52%) 1.6385\n",
      "14m 21s (54000 54%) 1.5485\n",
      "14m 51s (56000 56%) 1.5778\n",
      "15m 23s (58000 57%) 1.5349\n",
      "15m 53s (60000 60%) 1.4983\n",
      "16m 24s (62000 62%) 1.5419\n",
      "16m 54s (64000 64%) 1.4848\n",
      "17m 24s (66000 66%) 1.4984\n",
      "17m 55s (68000 68%) 1.4000\n",
      "18m 25s (70000 70%) 1.4210\n",
      "18m 55s (72000 72%) 1.3747\n",
      "19m 26s (74000 74%) 1.3388\n",
      "19m 56s (76000 76%) 1.3594\n",
      "20m 27s (78000 78%) 1.3486\n",
      "20m 57s (80000 80%) 1.3330\n",
      "21m 29s (82000 82%) 1.2647\n",
      "22m 0s (84000 84%) 1.3386\n",
      "22m 30s (86000 86%) 1.2891\n",
      "23m 2s (88000 88%) 1.2995\n",
      "23m 34s (90000 90%) 1.2618\n",
      "24m 5s (92000 92%) 1.2429\n",
      "24m 36s (94000 94%) 1.2986\n",
      "25m 7s (96000 96%) 1.3246\n",
      "25m 37s (98000 98%) 1.3716\n",
      "26m 8s (100000 100%) 1.4025\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    trainIters(encoder1, attn_decoder1, n_iters, print_every=print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je vous en de besoin de voir . <EOS>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = \"i love you\"\n",
    "output_words, attention = evaluate(encoder1, attn_decoder1, sentence)\n",
    "output_sentence = ' '.join(output_words)\n",
    "print(output_sentence)\n",
    "plt.figure()\n",
    "plt.matshow(attention.numpy())\n",
    "plt.savefig(\"./s2s_attn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源语言: you re wasting time .\n",
      "目的语言 vous gaspillez du temps .\n",
      "翻译结果: vous gaspillez du temps . <EOS>\n",
      " \n",
      "源语言: i m sorry i didn t recognize you .\n",
      "目的语言 je suis desole je ne vous ai pas reconnues .\n",
      "翻译结果: je suis desole je ne vous ai pas reconnue . <EOS>\n",
      " \n",
      "源语言: she is proficient in both spanish and italian .\n",
      "目的语言 elle est tres competente en espagnol et en italien .\n",
      "翻译结果: elle est tres fachee en espagnol et en italien . <EOS>\n",
      " \n",
      "源语言: you re too old for me .\n",
      "目的语言 vous etes trop vieille pour moi .\n",
      "翻译结果: vous etes trop vieille pour moi . <EOS>\n",
      " \n",
      "源语言: we re stuffed .\n",
      "目的语言 nous sommes gaves .\n",
      "翻译结果: nous sommes jeunes . <EOS>\n",
      " \n",
      "源语言: he is about my age .\n",
      "目的语言 il a environ mon age .\n",
      "翻译结果: il a environ peu pres mon age . <EOS>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存至 seq2seq_translation_model.pth\n"
     ]
    }
   ],
   "source": [
    "    model_path = \"seq2seq_translation_model.pth\"\n",
    "    torch.save({\n",
    "        'encoder_state_dict': encoder1.state_dict(),\n",
    "        'decoder_state_dict': attn_decoder1.state_dict(),\n",
    "        'input_lang': {\n",
    "            'name': input_lang.name,\n",
    "            'word2index': input_lang.word2index,\n",
    "            'index2word': input_lang.index2word,\n",
    "            'n_words': input_lang.n_words\n",
    "        },\n",
    "        'output_lang': {\n",
    "            'name': output_lang.name,\n",
    "            'word2index': output_lang.word2index,\n",
    "            'index2word': output_lang.index2word,\n",
    "            'n_words': output_lang.n_words\n",
    "        },\n",
    "        'hidden_size': hidden_size,\n",
    "        'max_length': MAX_LENGTH\n",
    "    }, model_path)\n",
    "    print(f\"模型已保存至 {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
